{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "18e65f8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "t= torch.randn(10,120,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "784c2cce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, [2, 3, 4], 5)"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq = [1,2,3,4,5]\n",
    "\n",
    "a,*b, c = seq\n",
    "\n",
    "a,b,c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "46e9ca91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [0, *seq] # similar to l=[0]; l.extend(seq); l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bf33226e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[119, 111, 114, 108, 100, 115,   0,   0,   0],\n",
       "        [ 98, 101,  97, 117, 116, 105, 102, 117, 108],\n",
       "        [119, 111, 114, 108, 100,   0,   0,   0,   0],\n",
       "        [ 60,  80,  65,  68,  62,   0,   0,   0,   0]], dtype=torch.uint8)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "words = ['worlds', 'beautiful', 'world', '<PAD>']\n",
    "\n",
    "def encode_8bit(words):\n",
    "    max_l = 0\n",
    "    ts_list = []\n",
    "    for w in words:\n",
    "        ts_list.append(torch.ByteTensor(list(bytes(w, 'utf8'))))\n",
    "        max_l = max(ts_list[-1].size()[0], max_l)\n",
    "\n",
    "    w_t = torch.zeros((len(ts_list), max_l), dtype=torch.uint8)\n",
    "    for i, ts in enumerate(ts_list):\n",
    "        w_t[i, 0:ts.size()[0]] = ts\n",
    "    return w_t\n",
    "\n",
    "encode_8bit(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b2299721",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "stop_words = set(stopwords.words('english')) \n",
    "\n",
    "def clean_and_encode(text, lemmatize=False , clean_punc=False, clean_stopwords=False):\n",
    "    \n",
    "    text = str(text) # in case of non-string values\n",
    "    text = text.lower()\n",
    "    text = TweetTokenizer().tokenize(text) # => list of tokens\n",
    "    \n",
    "    if lemmatize:\n",
    "        text = [WordNetLemmatizer().lemmatize(token) for token in text]\n",
    "\n",
    "    if clean_punc:\n",
    "        text = [token for token in text if token not in punctuation]\n",
    "    if clean_stopwords:\n",
    "        text = [token for token in text if token not in stop_words]\n",
    "    \n",
    "    return encode_8bit(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "930caa3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6, 7])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testtext = \"runin for senitur! #YOLO!\"\n",
    "clean_and_encode(testtext).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a0562ca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext.legacy.data import Field, BucketIterator, TabularDataset\n",
    "\n",
    "def get_datasets(device, batch_size=50):\n",
    "\n",
    "    # \"fields\" that process the columns in CSV files\n",
    "    Tokens = Field(tokenize = lambda x:TweetTokenizer().tokenize(x), lower=True, batch_first=True)\n",
    "#     Labels = torchtext.data.Field(batch_first=True)\n",
    "    fields = [('text', Tokens), ('parent_text', Tokens)]\n",
    "    \n",
    "    #Process from CSV files\n",
    "    train,test = TabularDataset.splits(\n",
    "            path='data', train='train.csv', test='test.csv',\n",
    "            format='csv', fields=fields, skip_header=True, \n",
    "            csv_reader_params = {'delimiter':'\\t','quotechar':'„ÄÅ'})\n",
    "\n",
    "    # build vocabularies based on what CSV files contained and create word2id mapping\n",
    "    Tokens.build_vocab(train)\n",
    "\n",
    "    #Batch iterator\n",
    "    train_batches,test_batches = BucketIterator.splits(\n",
    "            (train,test), batch_size=batch_size, shuffle=True, device=device,\n",
    "             sort_within_batch=True, sort_key=lambda x: len(x.text))\n",
    "    \n",
    "    return train_batches, test_batches, Tokens.vocab\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c8824827",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Example' object has no attribute 'text'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_1078096/1084755467.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_batches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_batches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvocab\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_datasets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cuda:0'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_1078096/4132179307.py\u001b[0m in \u001b[0;36mget_datasets\u001b[0;34m(device, batch_size)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;31m# build vocabularies based on what CSV files contained and create word2id mapping\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0mTokens\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild_vocab\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;31m#Batch iterator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/torchtext/legacy/data/field.py\u001b[0m in \u001b[0;36mbuild_vocab\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    290\u001b[0m                 \u001b[0msources\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msources\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 292\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    293\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msequential\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m                     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/torchtext/legacy/data/dataset.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, attr)\u001b[0m\n\u001b[1;32m    152\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mattr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfields\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexamples\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 154\u001b[0;31m                 \u001b[0;32myield\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    155\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Example' object has no attribute 'text'"
     ]
    }
   ],
   "source": [
    "train_batches, test_batches, vocab = get_datasets('cuda:0', batch_size=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "683c5f74",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchtext.datasets import AG_NEWS\n",
    "train_iter = AG_NEWS(split='train')   # Cf. batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "cf01141c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, \"Oil and Economy Cloud Stocks' Outlook (Reuters) Reuters - Soaring crude prices plus worries\\\\about the economy and the outlook for earnings are expected to\\\\hang over the stock market next week during the depth of the\\\\summer doldrums.\")\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "9be4e425",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "tokenizer = TweetTokenizer().tokenize\n",
    "# tokenizer = get_tokenizer('basic_english')\n",
    "\n",
    "def yield_tokens(data_iter):\n",
    "    for _, text in data_iter:\n",
    "        yield tokenizer(text)\n",
    "\n",
    "vocab = build_vocab_from_iterator(yield_tokens(train_iter), specials=[\"<unk>\"])\n",
    "vocab.set_default_index(vocab[\"<unk>\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "30629526",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[525, 24, 33, 5982]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab(['here', 'is', 'an', 'example'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "50059988",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>parent_id</th>\n",
       "      <th>subreddit_id</th>\n",
       "      <th>link_id</th>\n",
       "      <th>text</th>\n",
       "      <th>score</th>\n",
       "      <th>ups</th>\n",
       "      <th>author</th>\n",
       "      <th>controversiality</th>\n",
       "      <th>parent_link_id</th>\n",
       "      <th>parent_text</th>\n",
       "      <th>parent_score</th>\n",
       "      <th>parent_ups</th>\n",
       "      <th>parent_author</th>\n",
       "      <th>parent_controversiality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>c092j8m</td>\n",
       "      <td>t1_c092gss</td>\n",
       "      <td>t5_2qh2p</td>\n",
       "      <td>t3_8eyy3</td>\n",
       "      <td>This isn't Twitter: try to comment on the arti...</td>\n",
       "      <td>9582</td>\n",
       "      <td>9582</td>\n",
       "      <td>nraustinii</td>\n",
       "      <td>0</td>\n",
       "      <td>t3_8eyy3</td>\n",
       "      <td>Fucking faggot.</td>\n",
       "      <td>-7526</td>\n",
       "      <td>-7526</td>\n",
       "      <td>Glorificus</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>c4imcva</td>\n",
       "      <td>t1_c4im948</td>\n",
       "      <td>t5_2qh1i</td>\n",
       "      <td>t3_t0ynr</td>\n",
       "      <td>Well, it is exactly what it sounds like. It's ...</td>\n",
       "      <td>9531</td>\n",
       "      <td>9531</td>\n",
       "      <td>Lynfect</td>\n",
       "      <td>0</td>\n",
       "      <td>t3_t0ynr</td>\n",
       "      <td>Elaborate on this cum box, please.</td>\n",
       "      <td>3841</td>\n",
       "      <td>3841</td>\n",
       "      <td>eeeeevil</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>c0s4nfi</td>\n",
       "      <td>t1_c0s4lje</td>\n",
       "      <td>t5_2qh1i</td>\n",
       "      <td>t3_cf1n2</td>\n",
       "      <td>In soviet Russia, bomb disarms you!</td>\n",
       "      <td>8545</td>\n",
       "      <td>8545</td>\n",
       "      <td>CapnScumbone</td>\n",
       "      <td>0</td>\n",
       "      <td>t3_cf1n2</td>\n",
       "      <td>I don't live in Russia anymore, and I will not...</td>\n",
       "      <td>621</td>\n",
       "      <td>621</td>\n",
       "      <td>shady8x</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>c4ini33</td>\n",
       "      <td>t1_c4incln</td>\n",
       "      <td>t5_2qh1i</td>\n",
       "      <td>t3_t0ynr</td>\n",
       "      <td>\"runin for senitur! #YOLO!\"</td>\n",
       "      <td>7430</td>\n",
       "      <td>7430</td>\n",
       "      <td>[deleted]</td>\n",
       "      <td>0</td>\n",
       "      <td>t3_t0ynr</td>\n",
       "      <td>This just made me realize that future presiden...</td>\n",
       "      <td>4651</td>\n",
       "      <td>4651</td>\n",
       "      <td>drspg99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>c4imgel</td>\n",
       "      <td>t1_c4ima2e</td>\n",
       "      <td>t5_2qh1i</td>\n",
       "      <td>t3_t0ynr</td>\n",
       "      <td>You step motherfucker.</td>\n",
       "      <td>7173</td>\n",
       "      <td>7173</td>\n",
       "      <td>jbg89</td>\n",
       "      <td>0</td>\n",
       "      <td>t3_t0ynr</td>\n",
       "      <td>I have sex with my step mom when my dad isn't ...</td>\n",
       "      <td>4251</td>\n",
       "      <td>4251</td>\n",
       "      <td>audir8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id   parent_id subreddit_id   link_id  \\\n",
       "0  c092j8m  t1_c092gss     t5_2qh2p  t3_8eyy3   \n",
       "1  c4imcva  t1_c4im948     t5_2qh1i  t3_t0ynr   \n",
       "2  c0s4nfi  t1_c0s4lje     t5_2qh1i  t3_cf1n2   \n",
       "3  c4ini33  t1_c4incln     t5_2qh1i  t3_t0ynr   \n",
       "4  c4imgel  t1_c4ima2e     t5_2qh1i  t3_t0ynr   \n",
       "\n",
       "                                                text  score   ups  \\\n",
       "0  This isn't Twitter: try to comment on the arti...   9582  9582   \n",
       "1  Well, it is exactly what it sounds like. It's ...   9531  9531   \n",
       "2                In soviet Russia, bomb disarms you!   8545  8545   \n",
       "3                        \"runin for senitur! #YOLO!\"   7430  7430   \n",
       "4                             You step motherfucker.   7173  7173   \n",
       "\n",
       "         author  controversiality parent_link_id  \\\n",
       "0    nraustinii                 0       t3_8eyy3   \n",
       "1       Lynfect                 0       t3_t0ynr   \n",
       "2  CapnScumbone                 0       t3_cf1n2   \n",
       "3     [deleted]                 0       t3_t0ynr   \n",
       "4         jbg89                 0       t3_t0ynr   \n",
       "\n",
       "                                         parent_text  parent_score  \\\n",
       "0                                    Fucking faggot.         -7526   \n",
       "1                 Elaborate on this cum box, please.          3841   \n",
       "2  I don't live in Russia anymore, and I will not...           621   \n",
       "3  This just made me realize that future presiden...          4651   \n",
       "4  I have sex with my step mom when my dad isn't ...          4251   \n",
       "\n",
       "   parent_ups parent_author  parent_controversiality  \n",
       "0       -7526    Glorificus                        0  \n",
       "1        3841      eeeeevil                        0  \n",
       "2         621       shady8x                        0  \n",
       "3        4651       drspg99                        0  \n",
       "4        4251        audir8                        0  "
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.read_csv('data/comments_positive.csv')[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "90857648",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "a = torch.ones(20)\n",
    "b = torch.ones(12)\n",
    "c = torch.ones(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76c70e18",
   "metadata": {},
   "source": [
    "##### tens = torch.randn(50,150,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "3eea65b4",
   "metadata": {},
   "outputs": [
    {
     "ename": "ZeroDivisionError",
     "evalue": "integer division or modulo by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_1078096/2675465246.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;36m50\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mZeroDivisionError\u001b[0m: integer division or modulo by zero"
     ]
    }
   ],
   "source": [
    "50%0"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
